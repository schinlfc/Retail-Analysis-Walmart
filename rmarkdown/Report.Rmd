---
title: "Analysis Report--Walmart Sales Prediction"
author: "Sayorn Chin"
date: "07/30/2021"
output: rmarkdown::github_document
---

### Objective
##### The objective of this project is to develop a statistical model based on historical sales data. First, I use all 45 Walmart stores to derive some statistical values. Second, I use Store #1 to build statistical models in order to predict weekly sales. Lastly, I perform model selection and evaluation by incorporating different evaluation metrics.

### Required R libraries
```{r,warning=FALSE,message=FALSE}
load_libraries <- function(){
  library(openair)
  library(caret)
  library(ggplot2)
  library(lubridate)
  library(dplyr)
  library(tidyverse)
  library(tidyselect)
  library(vctrs)
  library(scales)
  library(zoo)
  library(forecast)
  library(Hmisc)
  library(corrplot)
  library(PerformanceAnalytics)
  library(ggfortify)
  library(car)
  library(patchwork)
  library(knitr)
  print("The libraries have been loaded .")
}
load_libraries()
```

### 1. Data preprocessing
```{r, warning=FALSE,message=FALSE}
# ++++++++++++++++++++++++++++
# DSet working directory
# ++++++++++++++++++++++++++++
setwd("/Users/schinlfc/data-science-R/retail-analysis-walmart/data")

# ++++++++++++++++++++++++++++
# Read csv file and assigned as df
# ++++++++++++++++++++++++++++
df <- read.csv("Walmart_Store_sales.csv")
# Get a summary of the data
summary(df)
# Check for missing values
sum(!complete.cases(df))
# Rename columns
df <- 
  df %>% 
  rename(
    store = Store,
    date = Date,
    weekly_sales = Weekly_Sales,
    holiday_flag = Holiday_Flag,
    temperature = Temperature,
    fuel_price = Fuel_Price,
    cpi = CPI,
    unemployment = Unemployment)
# Convert date to d-m-Y
df$date=as.Date(df$date,format="%d-%m-%Y")
```

### 2. Basic statistical results
```{r, warning=FALSE,message=FALSE}
## Which store has maximum sales?
df %>% 
  group_by(store) %>% summarise(weekly_sales =
  max(weekly_sales)) %>% arrange(desc(weekly_sales)) %>% head(1)
```
We can see that Store #14 has the largest weekly sales.

```{r, warning=FALSE,message=FALSE}
## Which store has maximum standard deviation?
df %>% 
  group_by(store) %>% summarise(weekly_sales = sd(weekly_sales)) %>%
  arrange(desc(weekly_sales)) %>% head(1)
```
We can see that Store #14 has the largest standard deviation.

```{r, warning=FALSE,message=FALSE}
## Which store/s has good quarterly growth rate in the third quarter of 2012
# Defining the start and end date of Q3
Q3 <- 
  selectByDate( 
    df,
    start = "2012-07-01",
    end = "2012-09-30")
# Defining the start and end date of Q2
Q2 <- 
  selectByDate( 
    df,
    start = "2012-04-01",
    end = "2012-06-30")
# Finding the total weekly sales of each store in Q3
Q3_weekly_sale <- 
  data.frame(Q3 %>% group_by(store) %>% 
  summarise(Q3_weekly_sales = sum(weekly_sales)))
# Finding the total weekly sales of each store in Q2
Q2_weekly_sale <- 
  data.frame(Q2 %>% group_by(store) %>% 
  summarise(Q2_weekly_sale = sum(weekly_sales)))
# Merging Q3 and Q2 data frame on store as a common column
Q3_Q2_merged <- 
  merge(Q3_weekly_sale,Q2_weekly_sale, by="store")
# Calculating growth rate in the third quarter of 2012
Q3_Q2_merged$growth_rate <-
  (((Q3_Q2_merged$Q3_weekly_sales)-(Q2_weekly_sale$Q2_weekly_sale))
   / (Q2_weekly_sale$Q2_weekly_sale)) * 100
# Round the growth rate to two decimal places
Q3_Q2_merged$growth_rate <- 
  round(Q3_Q2_merged$growth_rate, digits = 2)
# Get stores that have good quarterly growth rate in the third quarter of 2012
Q3_Q2_merged %>% 
  group_by(store) %>% arrange(desc(growth_rate)) %>% head(20)
```
The table shows that only 10 stores have good quarterly growth rate in the third quarter of 2012.

```{r, warning=FALSE,message=FALSE}
## Some holidays have a negative impact on sales. Find out holidays which have higher sales than the mean sales in non-holiday season for all stores together
# Weekly sales between nonholidays and holidays
df %>% group_by(holiday_flag) %>%
  summarise(mean_sales_of_nonholiday_and_holiday = 
  mean(weekly_sales)) 
# Create dummy variable for the dates of Super Bowl
df$super_bowl <- 
  ifelse(df$date == "2010-02-12" | df$date == "2011-02-11" | 
  df$date == "2012-02-10" | df$date == "2013-02-08", 1, 0)
# Create dummy variable for the dates of Labour Day
df$labour_day <- 
  ifelse(df$date == "2010-09-10" | df$date == "2011-09-09" | 
  df$date == "2012-09-07" | df$date == "2013-09-06", 1, 0)
# Create dummy variable for the dates of Thanksgiving
df$thanksgiving <- 
  ifelse(df$date == "2010-11-26" | df$date == "2011-11-25" | 
  df$date == "2012-11-23" | df$date == "2013-11-29", 1, 0)
# Create dummy variable for the dates of Christmas
df$christmas <- 
  ifelse(df$date == "2010-12-31" | df$date == "2011-12-30" | 
  df$date == "2012-12-28" | df$date == "2013-12-27", 1, 0)
# Mean weekly sales during Super Bowl
df %>% 
  group_by(super_bowl) %>% summarise(super_bowl_mean_sales = 
  mean(weekly_sales)) 
# Mean weekly sales during Labour Day
df %>% 
  group_by(labour_day) %>% summarise(labour_day_mean_sales = 
  mean(weekly_sales)) 
# Mean weekly sales during Thanksgiving
df %>% 
  group_by(thanksgiving) %>% summarise(thanksgiving_mean_sales = 
  mean(weekly_sales)) 
# Mean weekly sales during Christmas
df %>% 
  group_by(christmas) %>% summarise(christmas_mean_sales = 
  mean(weekly_sales)) 
```
Here, we can see that average weekly sales went up during Thanksgiving and Super Bowl but went down during both labour day and Christmas. Overall, sales went up during holiday season.  

```{r, warning=FALSE,message=FALSE}
### Provide a monthly and semester view of sales in units and give insights
# Split date into year, month and day.
df <- 
  df %>%
  separate(date, sep="-", into = c("year", "month", "day"))

# Plotting weekly sale distribution by month
ggplot(df, aes(x = month, y = weekly_sales/10000)) + # Scale by 10000
  geom_col() +
  geom_col(fill = "#00abff") +
  theme(text = element_text(size = 10, hjust = 0.5)) +
  theme_update(plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~year) +
  ggtitle("Weekly sales distribution by month for the years of 2010-2012") +
  xlab("Month") +
  ylab("Weekly Sales (in 10000)")
```

We can observe from the graph that highest sum of sales is recorded in between December-2010 to December-2011.

```{r, warning=FALSE,message=FALSE}
# Create a date column
df <-
  df %>%
  mutate(date = make_date(year, month, day))

# Plotting weekly sale distribution by semester
ggplot(df, aes(x = semester(date, with_year = TRUE), y = weekly_sales/100000)) + # Scale by 10000
  geom_col() +
  geom_col(fill = "#00abff") +
  theme(text = element_text(size = 10, hjust = 0.5)) +
  theme_update(plot.title = element_text(hjust = 0.5)) +
  ggtitle("Weekly sales distribution by semester") +
  xlab("Semester") +
  ylab("Weekly Sales (in 100000)")
```

We can observe from semester sales graph that at beginning of 1st semester of 2010 and 2nd semester of 2012 sales are lowest.

### 3. Data visualisation and statistical models
```{r, warning=FALSE,message=FALSE}
# First, I need to subset the dataset to only include Store #1 information by the following code:
df1 <- df[df$store == 1, ]
# Second, I need to split into train/test dataset and set seed for reproducible results
set.seed(123) 
sample_size <- floor(0.75 * nrow(df1))
train_index <- sample(seq_len(nrow(df1)), size = sample_size)
train <- df1[train_index, ]
test <- df1[-train_index, ]
```

#### 3.1 Data visualisation
```{r, fig1, fig.height = 3, fig.width = 5, warning=FALSE,message=FALSE}

ggplot(train, aes(x=temperature)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white") +
  geom_density(alpha=.2, fill="#FF6666") +
  ggtitle("Histogram plot of temprature") +
  xlab("Temperature") +
  ylab("Density")

ggplot(train, aes(x=fuel_price)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white") +
  geom_density(alpha=.2, fill="#FF6666") +
  ggtitle("Histogram plot of fuel price") +
  xlab("Fuel Price") +
  ylab("Density")

ggplot(train, aes(x=cpi)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white") +
  geom_density(alpha=.2, fill="#FF6666") +
  ggtitle("Histogram plot of consumer price index (CPI)") +
  xlab("CPI") +
  ylab("Density")

ggplot(train, aes(x=unemployment)) +
  geom_histogram(aes(y=..density..), colour="black", fill="white") +
  geom_density(alpha=.2, fill="#FF6666") +
  ggtitle("Histogram plot of unemployment rate") +
  xlab("Unemployment (%)") +
  ylab("Density")

ggplot(train, aes(x=weekly_sales/1000)) +
  geom_histogram(aes(y=..density..), colour="black", fill="white") +
  geom_density(alpha=.2, fill="#FF6666") +
  ggtitle("Histogram plot of weekly sales") +
  xlab("Weekly Sales (in 1000)") +
  ylab("Density")

ggplot(train, aes(x=log(weekly_sales))) +
  geom_histogram(aes(y=..density..), colour="black", fill="white") +
  geom_density(alpha=.2, fill="#FF6666") +
  ggtitle("Histogram plot of log weekly_sales") +
  xlab("Log Weekly Sales") +
  ylab("Density")

ggplot(train, aes(x=temperature, y=weekly_sales/1000)) +
  geom_point(shape=18, color="blue")+
  geom_smooth(method=lm,  linetype="dashed",
  color="darkred", fill="blue") +
  labs(title = "Scatter plot of temperature vs. weekly sales") +
  ylab("Weekly Sales (in 1000)") +
  xlab("Temperature")

ggplot(train, aes(x=temperature, y=log(weekly_sales))) +
  geom_point(shape=18, color="blue")+
  geom_smooth(method=lm,  linetype="dashed",
  color="darkred", fill="blue") +
  labs(title = "Scatter plot of temperature vs. log weekly sales") +
  ylab("Log Weekly Sales") +
  xlab("Temperature")
ggplot(train, aes(x=unemployment, y=log(weekly_sales))) + 
  geom_point(shape=18, color="blue")+
  geom_smooth(method=lm,  linetype="dashed",
              color="darkred", fill="blue") +
  labs(title = "Scatter plot of unemployment rate vs. log weekly 
  wales") +
  ylab("Log Weekly Sales") +
  xlab("Unemployment (%)")

ggplot(train, aes(x=cpi, y=weekly_sales/1000)) + 
  geom_point(shape=18, color="blue")+
  geom_smooth(method=lm,  linetype="dashed",
  color="darkred", fill="blue") +
  labs(title = "Scatter plot of CPI vs. weekly sales") +
  ylab("Weekly Sales (in 1000)") +
  xlab("CPI")

ggplot(train, aes(x=cpi, y=log(weekly_sales))) + 
  geom_point(shape=18, color="blue")+
  geom_smooth(method=lm,  linetype="dashed",
  color="darkred", fill="blue") +
  labs(title = "Scatter plot of CPI vs. log weekly sales") +
  ylab("Log Weekly Sales") +
  xlab("CPI")
```

From the nine figures above, temperature seems to be the only one that follows normal distribution, but it also appears to be negatively skewed. Furthermore, there is weakly linear relationship between temperature, fuel price, unemployment rate, consumer price index, and that of weakly sales and log weakly sales.

#### 3.2 Linear regression

##### 3.2.1 Model I
I will star by using the lm() function to fit a linear regression model for store #1 with weekly_sales as the response.
```{r, warning=FALSE,message=FALSE}
lm_fit1 <- 
  lm(weekly_sales ~ temperature + cpi + thanksgiving + 
  fuel_price + unemployment + super_bowl, data = train)
# Show results of the fitted regression
summary(lm_fit1) 
```
This model shows that consumer price index and Thanksgiving holiday are positively influence weekly sales, and are significant. For example, an increase in CPI means that a household has to spend more dollars to maintain the same standard of living; that's mostly bad for the households, but it can be good for businesses like Walmar. The R-squred and adjusted R-squared are quite low. This is due to the fact that the training set consists of only 107 observations. Thus, only about 28% of the variance for a weekly sales are explained by the independent variables in the model

Next, I examine some diagnostic plots. Four diagnostic plots shown below.
```{r, warning=FALSE,message=FALSE}
par(mfrow = c(2,2))
# Diagnostic analysis
autoplot(lm_fit1)
```

The Normal Q-Q plot, for example, reveals the error term is normally distributed.

##### 3.2.2 Model II 
I will perform a second fitted linear regression analysis by only including significant right-hand side variables.
```{r, warning=FALSE,message=FALSE}
lm_fit2 <- lm(weekly_sales ~ cpi + thanksgiving, data = train)
# Show results of the fitted regression
summary(lm_fit2) 
# Diagnostic analysis
par(mfrow = c(2,2))
autoplot(lm_fit2) 
```

As shown above, the second model performs worst in terms of R-squared and adjusted R-squared. This makes sense since each variable is regressed against all others, and what is left unexplained (residuals) is carried over. In a way, the regression process looks for explanations in the variance in the data, but it doesn't really excel at telling what is signal and what is noise.

##### 3.2.3 Model III
I had observed in histogram plot that weekly sales is positively skewed. Hence,  I will perform log transformation on the response variable.
```{r, warning=FALSE,message=FALSE}
lm_fit3 <- lm(log(weekly_sales) ~ temperature + cpi + 
  thanksgiving + fuel_price + unemployment + 
  super_bowl,data = train)
# Show results of the fitted regression
summary(lm_fit3)
# Diagnostic analysis
par(mfrow = c(2,2))
autoplot(lm_fit3)
```

This model shows that R-squared is improving from Model I to approximately 29%, but weekly sales are only significantly inluent consumper price index and Thanksgiving holiday.

##### 3.2.4 Model IV
Similar to Model III, I will perform log transformation on the dependent variable, but only including signifant independent variables. 
```{r, warning=FALSE,message=FALSE}
lm_fit4 <- lm(log(weekly_sales) ~ cpi + thanksgiving, data = train)
# Show results of the fitted regression
summary(lm_fit4)
# Diagnostic analysis
par(mfrow = c(2,2))
autoplot(lm_fit4)
```

This model performs a little bit better than Model II in terms of R-squared and adjusted R-squared. Furthermore, consumer price index becomes even more signifcant and is positively associated with weekly sales.

### 3. Model evaluation
This section performs various accuracy metrics for the four models by using the test dataset.

#### 3.1 Evaluation of Model I
```{r, warning=FALSE,message=FALSE}
#Fit the test dataset to the training Model I
lm_fit_pred1 <- predict(lm_fit1, newdata = test, type = "response")
```
Now, taking into consideration the test data, the correlation between actual values and predicted values can be used as a form of accuracy measure.

##### 3.1.1 Model I correlation accuracy
```{r, warning=FALSE,message=FALSE}
# Actuals and predicteds 
act_pred1 <- data.frame(cbind(actuals=test$weekly_sales,
  predicteds=lm_fit_pred1))
# Correlation accuracy
cor(act_pred1) 
```
Correlation shows a low value of approximately 16%, so it means that actuals values and predicted values have different directional movement.

Here an overview of the first 10 rows of the new dataframe composed by actual values and predicted values:
```{r, warning=FALSE,message=FALSE}
head(act_pred1, n=10)
```

##### 3.1.2 Model I min-max accuracy
A good metric to see how much they are close is the min-max accuracy, that considers the average between the minimum and the maximum prediction.
```{r, warning=FALSE,message=FALSE}
min_max1 <- 
  mean(apply(act_pred1, 1, min) / apply(act_pred1, 1, max))
# Show the result
print(min_max1) 
```
The result of 0.9462576 is a high value, and it means that the accuracy is very good. Note: ideally, result of 1 is for a nearly perfect prediction.

##### 3.1.3 Model I mean absolute percentage deviation
Mean absolute percentage deviation is so defined:
```{r, warning=FALSE,message=FALSE}
mape1 <- 
  mean(abs((act_pred1$predicteds -
  act_pred1$actuals))/act_pred1$actuals)
# show the result
print(mape1) 
```
The result of about 0.05580002 is low, and means a pretty good prediction accuracy. Note: MAPE can only be computed with respect to data that are guaranteed to be strictly positive.

#### 3.1 Evaluation of Model I
```{r, warning=FALSE,message=FALSE}
# Fit the test dataset to the training Model I
lm_fit_pred1 <- predict(lm_fit1, newdata = test, type = "response")
```
Now, taking into consideration the test data, the correlation between actuals values and predicted values can be used as a form of accuracy measure.

##### 3.1.1 Model I correlation accuracy
```{r, warning=FALSE,message=FALSE}
# Actuals and predicteds 
act_pred1 <- data.frame(cbind(actuals=test$weekly_sales,
  predicteds=lm_fit_pred1))
# Correlation accuracy
cor(act_pred1) 
```
Correlation shows a low value of approximately 16%, so it means that actuals values and predicted values have different directional movement.

Here an overview of the first 10 rows of the new dataframe composed by actual values and predicted values:
```{r, warning=FALSE,message=FALSE}
head(act_pred1, n=10)
```

##### 3.1.2 Model I min-max accuracy
A good metric to see how much they are close is the min-max accuracy, that considers the average between the minimum and the maximum prediction.
```{r, warning=FALSE,message=FALSE}
min_max1 <- 
  mean(apply(act_pred1, 1, min) / apply(act_pred1, 1, max))
# Show the result
print(min_max1) 
```
The result of 0.9462576 is a high value, and it means that the accuracy is very good. Note: ideally, result of 1 is for a nearly perfect prediction.

##### 3.1.3 Model I mean absolute percentage deviation
Mean absolute percentage deviation is so defined:
```{r, warning=FALSE,message=FALSE}
mape1 <- 
  mean(abs((act_pred1$predicteds -
  act_pred1$actuals))/act_pred1$actuals)
# show the result
print(mape1) 
```
The result of about 0.05580002 is low, and means a pretty good prediction accuracy. Note: MAPE can only be computed with respect to data that are guaranteed to be strictly positive.

#### 3.2 Evaluation of Model II
```{r, warning=FALSE,message=FALSE}
# Fit the test dataset to the training Model II
lm_fit_pred2 <- predict(lm_fit2, newdata = test, type = "response")
```

##### 3.2.1 Model II correlation accuracy
```{r, warning=FALSE,message=FALSE}
# Actuals and predicteds 
act_pred2 <- data.frame(cbind(actuals=test$weekly_sales, predicteds=lm_fit_pred2)) 
# Correlation accuracy
cor(act_pred2) 
```
Correlation shows a low value of approximately 6%, so it means that actuals values and predicted values have different directional movement.

Here an overview of the first 10 rows of the new dataframe composed by actual
```{r, warning=FALSE,message=FALSE}
# Actuals and predicteds
head(act_pred2, n=10)
```

##### 3.2.2 Model II min-max accuracy
```{r, warning=FALSE,message=FALSE}
min_max2 <- 
  mean(apply(act_pred2, 1, min) / apply(act_pred2, 1, max))
# Show the result
print(min_max2) 
```
The result of 0.9453381 is a high value, and it means that the accuracy is very good. 

##### 3.2.3 Model II mean absolute percentage deviation
```{r, warning=FALSE,message=FALSE}
mape2 <- 
  mean(abs((act_pred2$predicteds
  -act_pred2$actuals))/act_pred2$actuals)
# Show the result
print(mape2) 
```
The result of about 0.05631375 is low, and means a pretty good prediction accuracy.

#### 3.3 Evaluation of Model III
```{r, warning=FALSE,message=FALSE}
# Fit the test dataset to the training Model III
lm_fit_pred3 <- predict(lm_fit3, newdata = test, type = "response")
```

##### 3.3.1 Model III correlation accuracy
```{r, warning=FALSE,message=FALSE}
# Actuals and predicteds 
act_pred3 <- 
  data.frame(cbind(actuals=test$weekly_sales,
  predicteds=exp(lm_fit_pred3))) 
# Correlation accuracy
cor(act_pred3) 
```
Correlation shows a low value of approximately 15%, so it means that actuals values and predicted values have different directional movement.

Here an overview of the first 10 rows of the new dataframe composed by actual values and predicted values:
```{r, warning=FALSE,message=FALSE} 
head(act_pred3, n=10)
```

##### 3.3.2 Model III min-max accuracy
```{r, warning=FALSE,message=FALSE}
min_max3 <- 
  mean(apply(act_pred3, 1, min) / apply(act_pred3, 1, max))
# Show the result
print(min_max3) 
```
The result of 0.9464435 is a high value, and it means that the accuracy is very good.

##### 3.3.3 Model III mean absolute percentage deviation
```{r, warning=FALSE,message=FALSE}
# Mean absolute percentage deviation is so defined:
mape3 <- 
  mean(abs((act_pred3$predicteds
  -act_pred3$actuals))/act_pred3$actuals)
# Show the result
print(mape3)
```
The result of about 0.05532267 is low, and means a pretty good prediction accuracy.

#### 3.4 Evaluation of Model IV
```{r, warning=FALSE,message=FALSE}
# Fit the test dataset to the training Model IV
lm_fit_pred4 <- predict(lm_fit4, newdata = test, type = "response")
```

##### 3.4.1 Model IV correlation accuracy
```{r, warning=FALSE,message=FALSE}
# Actuals and predicteds 
act_pred4 <- 
  data.frame(cbind(actuals=test$weekly_sales,
  predicteds=exp(lm_fit_pred4))) 
# Correlation accuracy
cor(act_pred4) 
```
Correlation shows a low value of approximately 5.8%, so it means that actuals values and predicted values have different directional movement.

Here an overview of the first 10 rows of the new data frame composed by actual values and predicted values:
```{r, warning=FALSE,message=FALSE}
head(act_pred4, n=10)
```

##### 3.4.2 Model IV min-max accuracy
```{r, warning=FALSE,message=FALSE}
min_max4 <- 
  mean(apply(act_pred4, 1, min) / apply(act_pred4, 1, max))
# Show the result
print(min_max4) 
```
The result of 0.9455609 is a high value, and it means that the accuracy is very good.

##### 3.4.3 Model IV mean absolute percentage deviation
```{r, warning=FALSE,message=FALSE}
mape4 <- 
  mean(abs((act_pred4$predicteds
  -act_pred4$actuals))/act_pred4$actuals)
# show the result
print(mape4) 
```
The result of about 0.05588391 is low, and means a pretty good prediction accuracy.

### 3.5 Summary table
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
Models <- c("Model I", "Model II", "Model III", "Model IV")
R2 <- c(0.2794, 0.2036, 0.2879, 0.2158)
Adj_R2 <- c(0.2362, 0.1883, 0.2452, 0.2007)
Corr_accuracy <- c(0.1596404, 0.05554981, 0.1483811,
                          0.05760864)
Min_max_accuracy  = c(0.9462576, 0.9453381, 0.9464435, 0.9455609)
MAPE = c(0.05580002, 0.05631375, 0.05532267, 0.05588391)
table <- data.frame(Models, R2, Adj_R2, Corr_accuracy, Min_max_accuracy, MAPE)
knitr::kable(table, "pipe", col.names = c("Models", "R-squared",
  "Adjusted R-squared", "Correlation accuracy", "Min-max accuracy",
  "MAPE"))
```

### 4 Conclusion
##### This project aims to get insightful information on all 45 Walmart stores. I found that (1) Store #1 had the largest weekly sales from 2010--2012; (2) only 10 stores experienced positive third quarter growth in weekly sales from 2010--2012; (3) Thanksgiving holiday played a huge role in increasing weekly sales, followed by the Super Bowl. Surprisingly, during Christmas and Labour Day, average weekly sales across 45 stores went down from 2010--2012. Finally, modelling weekly sales prediction was a challenged for a numerous reasons: (1) I chose to focuse only on Store #1 and therefore, I had to deal with low number of observations (2) there were not enough variables to choose from for best modelling outcome. It would be beneficial if data on markdowns, store types, prices of good, distance and location of store, membership status, etc were available. Nontheless, I managed to make four models from the available data for Store #1. As noted in the summary table, it is clear that Model III performs the best for the most part of the accuracy metrics when using test dataset.  

### References
Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. (2013). _An Introduction to Statistical Learning : With Applications in R._ New York :Springer







